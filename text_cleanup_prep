#Analysis
import matplotlib.pyplot as plt
import matplotlib as mpl
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

import re
import pandas as pd
import numpy as np
import seaborn as sns
import string
import nltk
import warnings
from nltk.stem.porter import *
import spacy

#removing 

def cleanup_text(file, rem_item):
    r = re.findall(rem_item, file)
    for i in r:
        file = re.sub(i, "", file)
    return file
 
#remove handles
df["clean text"] = np.vectorize(cleanup_text)(df["text"], "@[\w]*")
df["clean text"].head()

#remove extreneous characters
df["clean text"] = df["clean text"].str.replace("can't", "cannot")

df["clean text"] = df["clean text"].str.replace("[^a-zA-Z#]", " ")
df["clean text"] = df["clean text"].apply(lambda x:" ".join([w for w in x.split() if len(w)>3])) #not ideal, need to change

nlp = spacy.load("en_core_web_sm")
text = str(df["clean text"])
doc = nlp(text)

tokens_list = [] 
for token in doc:
    tokens_list.append(token)

tokens_list
type(tokens_list)


text = df[df['clean text']]

#wordcloud
wordcloud = WordCloud(stopwords = STOPWORDS, collocations=True).generate(str(tokens_list))

plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()
